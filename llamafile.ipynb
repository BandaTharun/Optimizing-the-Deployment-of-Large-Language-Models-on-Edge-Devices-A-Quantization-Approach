{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'doctor', 'render', 'token', 'convert', 'build', 'develop', 'metapackage', 'inspect', 'pack', 'repo', 'verify', 'content-trust', 'server', 'index', 'debug', 'skeleton', 'env')\n"
     ]
    }
   ],
   "source": [
    "!conda activate llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcode_files\u001b[m\u001b[m/                        llamafileapi.ipynb\n",
      "\u001b[34medgedevice_inferencing_codefiles\u001b[m\u001b[m/  local_resource_usage.txt\n",
      "\u001b[34medgedevice_inferencing_codefiles-\u001b[m\u001b[m/ ollama.ipynb\n",
      "graph.ipynb                        \u001b[34mpi400\u001b[m\u001b[m/\n",
      "langchain.ipynb                    \u001b[34mreport \u001b[m\u001b[m/\n",
      "llama-cpp.ipynb                    resource_usage.txt\n",
      "llamafile _api_inference.ipynb     transformars.ipynb\n",
      "llamafile.ipynb                    try.py\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tharun/lammafile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tharun/opt/anaconda3/envs/llms/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /Users/Tharun/lammafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama.log      \u001b[31mllamafile.exe\u001b[m\u001b[m* main.log\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding permession \n",
    "!chmod a+x ./llamafile.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLAMAFILE(1)              BSD General Commands Manual             LLAMAFILE(1)\u001b[m\n",
      "\u001b[m\n",
      "\u001b[1mNAME\u001b[m\u001b[m\n",
      "     \u001b[1mllamafile\u001b[m â€” large language model runner\u001b[m\n",
      "\u001b[m\n",
      "\u001b[1mSYNOPSIS\u001b[m\u001b[m\n",
      "     \u001b[1mllamafile\u001b[m [\u001b[1m--server\u001b[m] [flags...] \u001b[1m-m\u001b[m \u001b[4mmodel.gguf\u001b[m [\u001b[1m--mmproj\u001b[m \u001b[4mvision.gguf\u001b[m]\u001b[m\n",
      "     \u001b[1mllamafile\u001b[m [\u001b[1m--cli\u001b[m] [flags...] \u001b[1m-m\u001b[m \u001b[4mmodel.gguf\u001b[m \u001b[1m-p\u001b[m \u001b[4mprompt\u001b[m\u001b[m\n",
      "     \u001b[1mllamafile\u001b[m [\u001b[1m--cli\u001b[m] [flags...] \u001b[1m-m\u001b[m \u001b[4mmodel.gguf\u001b[m \u001b[1m--mmproj\u001b[m \u001b[4mvision.gguf\u001b[m \u001b[1m--image\u001b[m\u001b[m\n",
      "               \u001b[4mgraphic.png\u001b[m \u001b[1m-p\u001b[m \u001b[4mprompt\u001b[m\u001b[m\n",
      "\u001b[m\n",
      "\u001b[1mDESCRIPTION\u001b[m\u001b[m\n",
      "     \u001b[1mllamafile\u001b[m is a large language model tool. It has use cases such as:\u001b[m\n",
      "\u001b[m\n",
      "     \u001b[1m-\u001b[m   Code completion\u001b[m\n",
      "     \u001b[1m-\u001b[m   Prose composition\u001b[m\n",
      "     \u001b[1m-\u001b[m   Chatbot that passes the Turing test\u001b[m\n",
      "     \u001b[1m-\u001b[m   Text/image summarization and analysis\u001b[m\n",
      "\u001b[m\n",
      "\u001b[1mOPTIONS\u001b[m\u001b[m\n",
      "     The following options are available:\u001b[m\n",
      "\u001b[m\n",
      "     \u001b[1m--version\u001b[m\u001b[m\n",
      "\u001b[7m/tmp/paginate.1v560s\u001b[m\u001b[K"
     ]
    }
   ],
   "source": [
    "# to start running the model \n",
    "!./llamafile.exe -m /Users/Tharun/llms/mistral-7b-v0.1.Q2_K.gguf -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":1710870798,\"level\":\"INFO\",\"function\":\"server_cli\",\"line\":2812,\"message\":\"build info\",\"build\":1500,\"commit\":\"a30b324\"}\n",
      "{\"timestamp\":1710870798,\"level\":\"INFO\",\"function\":\"server_cli\",\"line\":2815,\"message\":\"system info\",\"n_threads\":4,\"n_threads_batch\":-1,\"total_threads\":8,\"system_info\":\"AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \"}\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Users/Tharun/llms/mistral-7b-v0.1.Q2_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:   65 tensors\n",
      "llama_model_loader: - type q3_K:  160 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 2.87 GiB (3.41 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./llamafile.exe -m /Users/Tharun/llms/mistral-7b-v0.1.Q2_K.gguf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Metal GPU support successfully loaded\n",
      "{\"timestamp\":1712565341,\"level\":\"INFO\",\"function\":\"server_cli\",\"line\":2812,\"message\":\"build info\",\"build\":1500,\"commit\":\"a30b324\"}\n",
      "{\"timestamp\":1712565341,\"level\":\"INFO\",\"function\":\"server_cli\",\"line\":2815,\"message\":\"system info\",\"n_threads\":4,\"n_threads_batch\":-1,\"total_threads\":8,\"system_info\":\"AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \"}\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /Users/Tharun/llms/capybarahermes-2.5-mistral-7b.Q2_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = argilla_capybarahermes-2.5-mistral-7b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {% for message in messages %}{{'<|im_...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:  129 tensors\n",
      "llama_model_loader: - type q3_K:   64 tensors\n",
      "llama_model_loader: - type q4_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 2.53 GiB (3.00 BPW) \n",
      "llm_load_print_meta: general.name     = argilla_capybarahermes-2.5-mistral-7b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  2593.28 MiB, ( 2593.34 /  5461.34)\n",
      "llm_load_tensors: system memory used  = 2592.69 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2\n",
      "ggml_metal_init: picking default device: Apple M2\n",
      "ggml_metal_init: ggml.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/var/folders/tx/thqjy9l967l8bpqhyd8xsvjr0000gn/T/.llamafile/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8 (1008)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    62.00 MiB, ( 2655.97 /  5461.34)\n",
      "llama_kv_cache_init: VRAM kv self = 2.00 MB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 2655.98 /  5461.34)\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 76.19 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    73.02 MiB, ( 2728.98 /  5461.34)\n",
      "llama_new_context_with_model: VRAM scratch buffer: 73.00 MiB\n",
      "llama_new_context_with_model: total VRAM used: 73.00 MiB (model: 0.00 MiB, context: 73.00 MiB)\n",
      "Available slots:\n",
      " -> Slot 0 - max context: 512\n",
      "\n",
      "llama server listening at http://10.24.104.86:8080\n",
      "llama server listening at http://172.20.10.3:8080\n",
      "llama server listening at http://127.0.0.1:8080\n",
      "\n",
      "opening browser tab... (pass --nobrowser to disable)\n",
      "{\"timestamp\":1712565349,\"level\":\"INFO\",\"function\":\"server_cli\",\"line\":3289,\"message\":\"HTTP server listening\",\"port\":\"8080\",\"hostname\":\"0.0.0.0\"}\n",
      "all slots are idle and system prompt is empty, clear the KV cache\n",
      "{\"timestamp\":1712565352,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57469,\"status\":200,\"method\":\"GET\",\"path\":\"/\",\"params\":{}}\n",
      "{\"timestamp\":1712565352,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57469,\"status\":200,\"method\":\"GET\",\"path\":\"/index.js\",\"params\":{}}\n",
      "{\"timestamp\":1712565352,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57470,\"status\":200,\"method\":\"GET\",\"path\":\"/completion.js\",\"params\":{}}\n",
      "{\"timestamp\":1712565352,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57471,\"status\":200,\"method\":\"GET\",\"path\":\"/json-schema-to-grammar.mjs\",\"params\":{}}\n",
      "slot 0 is processing [task id: 0]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =   12780.72 ms /    48 tokens (  266.26 ms per token,     3.76 tokens per second)\n",
      "print_timings:        eval time =   15787.98 ms /    71 runs   (  222.37 ms per token,     4.50 tokens per second)\n",
      "print_timings:       total time =   28568.70 ms\n",
      "slot 0 released (120 tokens in cache)\n",
      "{\"timestamp\":1712565665,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57609,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 1]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =   12756.15 ms /    47 tokens (  271.41 ms per token,     3.68 tokens per second)\n",
      "print_timings:        eval time =   16679.99 ms /    76 runs   (  219.47 ms per token,     4.56 tokens per second)\n",
      "print_timings:       total time =   29436.14 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566090,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57718,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 2]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1759.00 ms /    47 tokens (   37.43 ms per token,    26.72 tokens per second)\n",
      "print_timings:        eval time =   16407.03 ms /    76 runs   (  215.88 ms per token,     4.63 tokens per second)\n",
      "print_timings:       total time =   18166.03 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566110,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57734,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 3]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1580.81 ms /    47 tokens (   33.63 ms per token,    29.73 tokens per second)\n",
      "print_timings:        eval time =   16374.48 ms /    76 runs   (  215.45 ms per token,     4.64 tokens per second)\n",
      "print_timings:       total time =   17955.29 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566128,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57740,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 4]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1640.43 ms /    47 tokens (   34.90 ms per token,    28.65 tokens per second)\n",
      "print_timings:        eval time =   14906.85 ms /    75 runs   (  198.76 ms per token,     5.03 tokens per second)\n",
      "print_timings:       total time =   16547.29 ms\n",
      "slot 0 released (123 tokens in cache)\n",
      "{\"timestamp\":1712566145,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57754,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 5]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1877.14 ms /    47 tokens (   39.94 ms per token,    25.04 tokens per second)\n",
      "print_timings:        eval time =   16181.83 ms /    76 runs   (  212.92 ms per token,     4.70 tokens per second)\n",
      "print_timings:       total time =   18058.97 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566163,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57761,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 6]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1568.91 ms /    47 tokens (   33.38 ms per token,    29.96 tokens per second)\n",
      "print_timings:        eval time =   15870.74 ms /    76 runs   (  208.83 ms per token,     4.79 tokens per second)\n",
      "print_timings:       total time =   17439.65 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566181,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57768,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 7]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1882.92 ms /    47 tokens (   40.06 ms per token,    24.96 tokens per second)\n",
      "print_timings:        eval time =   14954.75 ms /    76 runs   (  196.77 ms per token,     5.08 tokens per second)\n",
      "print_timings:       total time =   16837.67 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566199,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57774,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 8]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1945.69 ms /    47 tokens (   41.40 ms per token,    24.16 tokens per second)\n",
      "print_timings:        eval time =   13009.15 ms /    75 runs   (  173.46 ms per token,     5.77 tokens per second)\n",
      "print_timings:       total time =   14954.84 ms\n",
      "slot 0 released (123 tokens in cache)\n",
      "{\"timestamp\":1712566214,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57779,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 9]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1478.18 ms /    47 tokens (   31.45 ms per token,    31.80 tokens per second)\n",
      "print_timings:        eval time =   14610.45 ms /    76 runs   (  192.24 ms per token,     5.20 tokens per second)\n",
      "print_timings:       total time =   16088.64 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566230,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57785,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 10]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1600.83 ms /    47 tokens (   34.06 ms per token,    29.36 tokens per second)\n",
      "print_timings:        eval time =   14809.57 ms /    76 runs   (  194.86 ms per token,     5.13 tokens per second)\n",
      "print_timings:       total time =   16410.40 ms\n",
      "slot 0 released (124 tokens in cache)\n",
      "{\"timestamp\":1712566247,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57791,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 11]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    9787.53 ms /    49 tokens (  199.75 ms per token,     5.01 tokens per second)\n",
      "print_timings:        eval time =   67889.30 ms /   367 runs   (  184.98 ms per token,     5.41 tokens per second)\n",
      "print_timings:       total time =   77676.83 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567069,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":57979,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 12]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1579.24 ms /    49 tokens (   32.23 ms per token,    31.03 tokens per second)\n",
      "print_timings:        eval time =   59210.31 ms /   367 runs   (  161.34 ms per token,     6.20 tokens per second)\n",
      "print_timings:       total time =   60789.54 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567129,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58008,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 13]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1735.34 ms /    49 tokens (   35.42 ms per token,    28.24 tokens per second)\n",
      "print_timings:        eval time =   58635.71 ms /   367 runs   (  159.77 ms per token,     6.26 tokens per second)\n",
      "print_timings:       total time =   60371.05 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567190,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58023,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 14]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1215.24 ms /    49 tokens (   24.80 ms per token,    40.32 tokens per second)\n",
      "print_timings:        eval time =   60076.42 ms /   367 runs   (  163.70 ms per token,     6.11 tokens per second)\n",
      "print_timings:       total time =   61291.66 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567251,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58039,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 15]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1608.95 ms /    49 tokens (   32.84 ms per token,    30.45 tokens per second)\n",
      "print_timings:        eval time =   64553.81 ms /   367 runs   (  175.90 ms per token,     5.69 tokens per second)\n",
      "print_timings:       total time =   66162.76 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567318,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58071,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 16]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1228.67 ms /    49 tokens (   25.07 ms per token,    39.88 tokens per second)\n",
      "print_timings:        eval time =   57430.87 ms /   367 runs   (  156.49 ms per token,     6.39 tokens per second)\n",
      "print_timings:       total time =   58659.55 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567377,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58091,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 17]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1593.78 ms /    49 tokens (   32.53 ms per token,    30.74 tokens per second)\n",
      "print_timings:        eval time =   59346.71 ms /   367 runs   (  161.71 ms per token,     6.18 tokens per second)\n",
      "print_timings:       total time =   60940.49 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567438,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58106,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 18]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    3371.61 ms /    49 tokens (   68.81 ms per token,    14.53 tokens per second)\n",
      "print_timings:        eval time =   61638.16 ms /   367 runs   (  167.95 ms per token,     5.95 tokens per second)\n",
      "print_timings:       total time =   65009.77 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567504,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58124,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 19]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1514.09 ms /    49 tokens (   30.90 ms per token,    32.36 tokens per second)\n",
      "print_timings:        eval time =   56291.40 ms /   367 runs   (  153.38 ms per token,     6.52 tokens per second)\n",
      "print_timings:       total time =   57805.49 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567562,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58140,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 20]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1727.60 ms /    49 tokens (   35.26 ms per token,    28.36 tokens per second)\n",
      "print_timings:        eval time =   62899.31 ms /   367 runs   (  171.39 ms per token,     5.83 tokens per second)\n",
      "print_timings:       total time =   64626.90 ms\n",
      "slot 0 released (417 tokens in cache)\n",
      "{\"timestamp\":1712567627,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58157,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 21]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1689.42 ms /    48 tokens (   35.20 ms per token,    28.41 tokens per second)\n",
      "print_timings:        eval time =    7331.09 ms /    48 runs   (  152.73 ms per token,     6.55 tokens per second)\n",
      "print_timings:       total time =    9020.51 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567636,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58173,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 22]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1210.97 ms /    48 tokens (   25.23 ms per token,    39.64 tokens per second)\n",
      "print_timings:        eval time =    7293.25 ms /    48 runs   (  151.94 ms per token,     6.58 tokens per second)\n",
      "print_timings:       total time =    8504.22 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567645,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58177,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 23]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1187.63 ms /    48 tokens (   24.74 ms per token,    40.42 tokens per second)\n",
      "print_timings:        eval time =    6936.95 ms /    48 runs   (  144.52 ms per token,     6.92 tokens per second)\n",
      "print_timings:       total time =    8124.58 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567653,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58181,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 24]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1583.69 ms /    48 tokens (   32.99 ms per token,    30.31 tokens per second)\n",
      "print_timings:        eval time =    8392.28 ms /    48 runs   (  174.84 ms per token,     5.72 tokens per second)\n",
      "print_timings:       total time =    9975.97 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567663,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58185,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 25]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1804.48 ms /    48 tokens (   37.59 ms per token,    26.60 tokens per second)\n",
      "print_timings:        eval time =    7762.70 ms /    48 runs   (  161.72 ms per token,     6.18 tokens per second)\n",
      "print_timings:       total time =    9567.18 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567673,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58192,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 26]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1704.60 ms /    48 tokens (   35.51 ms per token,    28.16 tokens per second)\n",
      "print_timings:        eval time =    7312.85 ms /    48 runs   (  152.35 ms per token,     6.56 tokens per second)\n",
      "print_timings:       total time =    9017.44 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567682,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58196,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 27]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1155.88 ms /    48 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
      "print_timings:        eval time =    7811.83 ms /    48 runs   (  162.75 ms per token,     6.14 tokens per second)\n",
      "print_timings:       total time =    8967.71 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567691,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58200,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 28]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1444.24 ms /    48 tokens (   30.09 ms per token,    33.24 tokens per second)\n",
      "print_timings:        eval time =    8199.63 ms /    48 runs   (  170.83 ms per token,     5.85 tokens per second)\n",
      "print_timings:       total time =    9643.88 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567700,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58204,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 29]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1433.89 ms /    48 tokens (   29.87 ms per token,    33.48 tokens per second)\n",
      "print_timings:        eval time =    9850.15 ms /    48 runs   (  205.21 ms per token,     4.87 tokens per second)\n",
      "print_timings:       total time =   11284.04 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567712,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58208,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 30]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1399.08 ms /    48 tokens (   29.15 ms per token,    34.31 tokens per second)\n",
      "print_timings:        eval time =    9805.95 ms /    48 runs   (  204.29 ms per token,     4.89 tokens per second)\n",
      "print_timings:       total time =   11205.04 ms\n",
      "slot 0 released (97 tokens in cache)\n",
      "{\"timestamp\":1712567723,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58213,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 31]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1510.10 ms /    48 tokens (   31.46 ms per token,    31.79 tokens per second)\n",
      "print_timings:        eval time =   30829.26 ms /   191 runs   (  161.41 ms per token,     6.20 tokens per second)\n",
      "print_timings:       total time =   32339.35 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712567756,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58218,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 32]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1619.23 ms /    48 tokens (   33.73 ms per token,    29.64 tokens per second)\n",
      "print_timings:        eval time =   32159.99 ms /   191 runs   (  168.38 ms per token,     5.94 tokens per second)\n",
      "print_timings:       total time =   33779.22 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712567790,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58226,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 33]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1734.81 ms /    48 tokens (   36.14 ms per token,    27.67 tokens per second)\n",
      "print_timings:        eval time =   36241.01 ms /   191 runs   (  189.74 ms per token,     5.27 tokens per second)\n",
      "print_timings:       total time =   37975.82 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712567828,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58236,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 34]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1090.38 ms /    48 tokens (   22.72 ms per token,    44.02 tokens per second)\n",
      "print_timings:        eval time =   34587.30 ms /   191 runs   (  181.09 ms per token,     5.52 tokens per second)\n",
      "print_timings:       total time =   35677.68 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712567864,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58246,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 35]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1355.60 ms /    48 tokens (   28.24 ms per token,    35.41 tokens per second)\n",
      "print_timings:        eval time =   32996.05 ms /   191 runs   (  172.75 ms per token,     5.79 tokens per second)\n",
      "print_timings:       total time =   34351.65 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712567898,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58260,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 36]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1627.40 ms /    48 tokens (   33.90 ms per token,    29.49 tokens per second)\n",
      "print_timings:        eval time =   35128.71 ms /   191 runs   (  183.92 ms per token,     5.44 tokens per second)\n",
      "print_timings:       total time =   36756.11 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712567935,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58275,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 37]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1735.93 ms /    48 tokens (   36.17 ms per token,    27.65 tokens per second)\n",
      "print_timings:        eval time =   33264.47 ms /   191 runs   (  174.16 ms per token,     5.74 tokens per second)\n",
      "print_timings:       total time =   35000.40 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712567971,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58288,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 38]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1518.18 ms /    48 tokens (   31.63 ms per token,    31.62 tokens per second)\n",
      "print_timings:        eval time =   32155.20 ms /   191 runs   (  168.35 ms per token,     5.94 tokens per second)\n",
      "print_timings:       total time =   33673.38 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712568005,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58300,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 39]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1318.62 ms /    48 tokens (   27.47 ms per token,    36.40 tokens per second)\n",
      "print_timings:        eval time =   34907.29 ms /   191 runs   (  182.76 ms per token,     5.47 tokens per second)\n",
      "print_timings:       total time =   36225.92 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712568041,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58310,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n",
      "slot 0 is processing [task id: 40]\n",
      "slot 0 : kv cache rm - [0, end)\n",
      "\n",
      "print_timings: prompt eval time =    1372.72 ms /    48 tokens (   28.60 ms per token,    34.97 tokens per second)\n",
      "print_timings:        eval time =   30593.22 ms /   191 runs   (  160.17 ms per token,     6.24 tokens per second)\n",
      "print_timings:       total time =   31965.94 ms\n",
      "slot 0 released (240 tokens in cache)\n",
      "{\"timestamp\":1712568073,\"level\":\"INFO\",\"function\":\"log_server_request\",\"line\":2741,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":58320,\"status\":200,\"method\":\"POST\",\"path\":\"/v1/chat/completions\",\"params\":{}}\n"
     ]
    }
   ],
   "source": [
    "# to start running the model and access it using api \n",
    "\n",
    "!./llamafile.exe -m /Users/Tharun/llms/capybarahermes-2.5-mistral-7b.Q2_K.gguf --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log start\n",
      "warning: this OS doesn't support pledge() security\n",
      "main: llamafile version 0.6.0\n",
      "main: seed  = 1710872980\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /Users/Tharun/llms/capybarahermes-2.5-mistral-7b.Q2_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = argilla_capybarahermes-2.5-mistral-7b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {% for message in messages %}{{'<|im_...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:  129 tensors\n",
      "llama_model_loader: - type q3_K:   64 tensors\n",
      "llama_model_loader: - type q4_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 2.53 GiB (3.00 BPW) \n",
      "llm_load_print_meta: general.name     = argilla_capybarahermes-2.5-mistral-7b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n"
     ]
    }
   ],
   "source": [
    "!./llamafile.exe -m /Users/Tharun/llms/capybarahermes-2.5-mistral-7b.Q2_K.gguf -p \"what is capital of italy \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0df86693d46cb4fa165d42afe4c34e25eb5aee45096910808bcdd8709ee78db2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
